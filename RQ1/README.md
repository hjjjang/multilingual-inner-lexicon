## 1. dataset_selection.py

This script processes Wikipedia data in multiple languages (English, German, and Korean) to extract and analyze noun frequencies. It performs the following:

1. **Load Data**: Fetches Wikipedia text data for a specified language and sample size.
2. **Extract Nouns**: Identifies nouns using language-specific tools:
   - **English**: NLTK
   - **German**: Stanza
   - **Korean**: Kiwi
3. **Analyze Frequencies**: Counts noun occurrences and filters results based on language rules.
4. **Save Results**: Outputs noun frequencies to a CSV file.

The script ensures efficient processing and avoids overwriting existing output files.

## 2. data.py

This script handles the generation and analysis of real and non-real words using tokenizers for multiple languages (English, German, and Korean). It performs the following:

1. **Load Dataset**: Loads noun datasets for the specified language.
2. **Tokenization**: Uses pre-trained tokenizers (e.g., Babel-9B, Gemma-12B, Llama-2-7B) to tokenize words and analyze token distributions.
3. **Generate Words**:
   - **Real Words**: Samples real words based on token counts and frequency quantiles.
   - **Non-Words**: Generates non-words by combining tokens from real words.
4. **Comparison**: Compares tokenization results across different tokenizers.
5. **Save Results**: Outputs tokenized data and word samples to CSV files.

The script supports configuration through JSON files and includes options for visualizing token distributions.

## 3. classification.py

This script performs classification of real and non-real words using tokenized data and pre-trained language models. It includes the following steps:

1. **Model Initialization**: Loads pre-trained models (e.g., Babel-9B, Gemma-12B, Llama-2-7B) and tokenizers for the specified language.
2. **Feature Extraction**: Extracts hidden states from tokenized words for specific layers of the model.
3. **Data Preparation**: Converts tokenized words into feature vectors and encodes labels for classification.
4. **KNN Classification**:
   - Trains a K-Nearest Neighbors (KNN) classifier on the extracted features.
   - Evaluates performance using metrics like accuracy, precision, recall, and F1-score.
5. **Save Results**: Outputs evaluation results to a CSV file.

The script supports GPU acceleration and processes datasets generated by `data.py`.

## 4. eval_analysis.py
