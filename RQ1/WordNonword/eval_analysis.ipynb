{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = \"/home/hyujang/multilingual-inner-lexicon/output/RQ1/WordNonword/all-token_words3\"\n",
    "folder_path = \"/home/hyujang/multilingual-inner-lexicon/output/RQ1/WordNonword/two-token_words2\"\n",
    "dataset_paths = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "# Define colors for each model\n",
    "model_colors = {\n",
    "    \"Babel-9B-Chat\": \"#66c2a5\",\n",
    "    \"gemma-3-12b-it\": \"#fc8d62\",\n",
    "    \"Llama-2-7b-chat-hf\": \"#e78ac3\"\n",
    "}\n",
    "\n",
    "# Define colors for each language\n",
    "language_colors = {\n",
    "    \"English\": \"#1f77b4\",\n",
    "    \"Korean\": \"#ff7f0e\",\n",
    "    \"German\": \"#2ca02c\"\n",
    "}\n",
    "\n",
    "# Define line styles for each model\n",
    "model_styles = {\n",
    "    \"Babel-9B-Chat\": \"-\",\n",
    "    \"gemma-3-12b-it\": \"--\",\n",
    "    \"Llama-2-7b-chat-hf\": \":\"\n",
    "}\n",
    "\n",
    "languague_styles = {\n",
    "    \"English\": \"-\",\n",
    "    \"Korean\": \"--\",\n",
    "    \"German\": \":\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find best n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_across_datasets(dataset_paths):\n",
    "    \"\"\"\n",
    "    Plots accuracy for each dataset as a line, grouped by language with the same color.\n",
    "\n",
    "    Args:\n",
    "    - dataset_paths (list): List of file paths to the datasets.\n",
    "    - language_colors (dict): Dictionary mapping languages to colors.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for dataset_path in dataset_paths:\n",
    "        # Extract language and tokenizer from the filename\n",
    "        filename = os.path.basename(dataset_path)\n",
    "        language_match = re.search(r'_(English|Korean|German)[-_]', filename)\n",
    "        language = language_match.group(1) if language_match else \"Unknown\"\n",
    "        tokenizer_match = re.search(r'knn_eval_results_([^_]+)_', filename)\n",
    "        tokenizer = tokenizer_match.group(1) if tokenizer_match else \"Unknown\"\n",
    "\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(dataset_path)\n",
    "        df = df[df[\"n_neighbors\"] <= 10]\n",
    "\n",
    "        # Group by n_neighbors and calculate the mean accuracy\n",
    "        mean_accuracy = df.groupby(\"n_neighbors\")[\"Accuracy\"].mean().reset_index()\n",
    "\n",
    "        # Plot the line for this dataset\n",
    "        sns.lineplot(\n",
    "            data=mean_accuracy,\n",
    "            x=\"n_neighbors\",\n",
    "            y=\"Accuracy\",\n",
    "            label=f\"{language} ({tokenizer})\",\n",
    "            color=language_colors.get(language, \"black\"), \n",
    "            # color=model_colors.get(tokenizer, \"black\"), \n",
    "            linestyle=model_styles.get(tokenizer, \"dashdot\"),\n",
    "            # linestyle=language_styles.get(language, \"-\"),\n",
    "            marker=\"o\"\n",
    "        )\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    plt.xlabel(\"n_neighbors\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "    plt.title(\"Accuracy Across Datasets by n_neighbors\", fontsize=14)\n",
    "    plt.legend(title=\"Dataset\", fontsize=10, loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_accuracy_across_datasets(dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def find_best_n_neighbors(dataset_paths):\n",
    "    \"\"\"\n",
    "    Finds the best n_neighbors value across multiple datasets based on average accuracy.\n",
    "\n",
    "    Args:\n",
    "    - dataset_paths (list): List of file paths to the datasets.\n",
    "\n",
    "    Returns:\n",
    "    - int: The best n_neighbors value.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    for dataset_path in dataset_paths:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(os.path.join(\"/home/hyujang/multilingual-inner-lexicon\", dataset_path))\n",
    "        df = df[df[\"n_neighbors\"] <= 10]\n",
    "        # Group by n_neighbors and calculate the mean accuracy\n",
    "        mean_accuracy = df.groupby(\"n_neighbors\")[\"Accuracy\"].mean().reset_index()\n",
    "        mean_accuracy[\"dataset\"] = os.path.basename(dataset_path)  # Add dataset name for reference\n",
    "        all_results.append(mean_accuracy)\n",
    "\n",
    "    # Combine results from all datasets\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "    # Calculate the overall average accuracy for each n_neighbors value\n",
    "    overall_mean_accuracy = combined_results.groupby(\"n_neighbors\")[\"Accuracy\"].mean()\n",
    "\n",
    "    # Find the n_neighbors value with the highest average accuracy\n",
    "    best_n_neighbors = overall_mean_accuracy.idxmax()\n",
    "    best_accuracy = overall_mean_accuracy.max()\n",
    "\n",
    "    print(f\"Best n_neighbors: {best_n_neighbors} with average accuracy: {best_accuracy:.4f}\")\n",
    "    return best_n_neighbors\n",
    "\n",
    "best_n_neighbors = find_best_n_neighbors(dataset_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot knn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_neighbors_5_accuracy(dataset_paths, language_colors, model_styles):\n",
    "    \"\"\"\n",
    "    Plots accuracy for n_neighbors = 5 for each dataset, grouped by language (color) and model (line style).\n",
    "\n",
    "    Args:\n",
    "    - dataset_paths (list): List of file paths to the datasets.\n",
    "    - language_colors (dict): Dictionary mapping languages to colors.\n",
    "    - model_styles (dict): Dictionary mapping models to line styles.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for dataset_path in dataset_paths:\n",
    "        # Extract language and tokenizer from the filename\n",
    "        filename = os.path.basename(dataset_path)\n",
    "        language = filename.split(\"_\")[4].split(\"-\")[0]  # Extract language (e.g., \"English\", \"Korean\", \"German\")\n",
    "        model = filename.split(\"_\")[3]  # Extract tokenizer (e.g., \"Babel-9B-Chat\")\n",
    "\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(os.path.join(\"/home/hyujang/multilingual-inner-lexicon\", dataset_path))\n",
    "\n",
    "        # Filter for n_neighbors = 5\n",
    "        filtered_df = df[df[\"n_neighbors\"] == best_n_neighbors]\n",
    "\n",
    "        # Plot the line for this dataset\n",
    "        sns.lineplot(\n",
    "            data=filtered_df,\n",
    "            x=\"Layer\",\n",
    "            y=\"Accuracy\",\n",
    "            label=f\"{language} ({model})\",\n",
    "            # label=filename,\n",
    "            color=language_colors.get(language, \"black\"),  # Use the color for the language\n",
    "            linestyle=model_styles.get(model, \"dashdot\"),  # Use the line style for the model\n",
    "            marker=\"o\"\n",
    "        )\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    plt.xlabel(\"Layer\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "    plt.title(f\"Accuracy for n_neighbors = {best_n_neighbors} Across Datasets\", fontsize=14)\n",
    "    plt.legend(title=\"Dataset\", fontsize=10, loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_n_neighbors_5_accuracy(dataset_paths, language_colors, model_styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_neighbors_5_accuracy_by_language(dataset_paths, language_colors, model_styles, metric=\"Accuracy\"):\n",
    "    \"\"\"\n",
    "    Creates separate subplots for each language, showing accuracy for n_neighbors = 5 for all models.\n",
    "\n",
    "    Args:\n",
    "    - dataset_paths (list): List of file paths to the datasets.\n",
    "    - language_colors (dict): Dictionary mapping languages to colors.\n",
    "    - model_styles (dict): Dictionary mapping models to line styles.\n",
    "    \"\"\"\n",
    "    # Group datasets by language\n",
    "    language_datasets = {\"English\": [], \"Korean\": [], \"German\": []}\n",
    "    for dataset_path in dataset_paths:\n",
    "        filename = os.path.basename(dataset_path)\n",
    "        language = filename.split(\"_\")[4].split(\"-\")[0]  # Extract language\n",
    "        language_datasets[language].append(dataset_path)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(8, 12), sharey=True)\n",
    "    for ax, (language, paths) in zip(axes, language_datasets.items()):\n",
    "        max_y = 0\n",
    "        for dataset_path in paths:\n",
    "            # Extract model from the filename\n",
    "            filename = os.path.basename(dataset_path)\n",
    "            model = filename.split(\"_\")[3]  # Extract tokenizer (e.g., \"Babel-9B-Chat\")\n",
    "\n",
    "\n",
    "            # Load the dataset\n",
    "            df = pd.read_csv(os.path.join(\"/home/hyujang/multilingual-inner-lexicon\", dataset_path))\n",
    "\n",
    "            # Filter for n_neighbors = 5\n",
    "            filtered_df = df[df[\"n_neighbors\"] == best_n_neighbors]\n",
    "\n",
    "            # Plot the line for this dataset\n",
    "            sns.lineplot(\n",
    "                data=filtered_df,\n",
    "                x=\"Layer\",\n",
    "                y=f\"{metric}\",\n",
    "                label=model,\n",
    "                color=model_colors.get(model, \"black\"),\n",
    "                # color=language_colors.get(language, \"black\"),  # Use the color for the language\n",
    "                # linestyle=model_styles.get(model, \"-\"),  # Use the line style for the model\n",
    "                marker=\"o\",\n",
    "                ax=ax\n",
    "            )\n",
    "            \n",
    "            max_y = max(max_y, filtered_df[f\"{metric}\"].max())\n",
    "\n",
    "        # Customize each subplot\n",
    "        ax.set_title(f\"{language} (n_neighbors = {best_n_neighbors})\", fontsize=14)\n",
    "        ax.set_xlabel(\"Layer\", fontsize=12)\n",
    "        ax.set_ylabel(f\"{metric}\", fontsize=12)\n",
    "        ax.legend(title=\"Model\", fontsize=10, loc=\"best\")\n",
    "        ax.grid(True)\n",
    "        # ax.set_ylim(0, max_y + 0.05)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_n_neighbors_5_accuracy_by_language(dataset_paths, language_colors, model_styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_neighbors_5_accuracy_by_model(dataset_paths, model_colors, language_styles):\n",
    "    \"\"\"\n",
    "    Creates separate subplots for each model, showing accuracy for n_neighbors = 5 for all languages.\n",
    "\n",
    "    Args:\n",
    "    - dataset_paths (list): List of file paths to the datasets.\n",
    "    - model_colors (dict): Dictionary mapping models to colors.\n",
    "    - language_styles (dict): Dictionary mapping languages to line styles.\n",
    "    \"\"\"\n",
    "    # Group datasets by model\n",
    "    model_datasets = {\"Babel-9B-Chat\": [], \"gemma-3-12b-it\": [], \"Llama-2-7b-chat-hf\": []}\n",
    "    for dataset_path in dataset_paths:\n",
    "        filename = os.path.basename(dataset_path)\n",
    "        model = filename.split(\"_\")[3]  # Extract model\n",
    "        model_datasets[model].append(dataset_path)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(8, 12), sharey=True)\n",
    "    for ax, (model, paths) in zip(axes, model_datasets.items()):\n",
    "        max_y = 0\n",
    "        for dataset_path in paths:\n",
    "            # Extract language from the filename\n",
    "            filename = os.path.basename(dataset_path)\n",
    "            language = filename.split(\"_\")[4].split(\"-\")[0]  # Extract language\n",
    "\n",
    "            # Load the dataset\n",
    "            df = pd.read_csv(os.path.join(\"/home/hyujang/multilingual-inner-lexicon\", dataset_path))\n",
    "\n",
    "            # Filter for n_neighbors = 5\n",
    "            filtered_df = df[df[\"n_neighbors\"] == best_n_neighbors]\n",
    "\n",
    "            # Plot the line for this dataset\n",
    "            sns.lineplot(\n",
    "                data=filtered_df,\n",
    "                x=\"Layer\",\n",
    "                y=\"Accuracy\",\n",
    "                label=language,\n",
    "                # color=model_colors.get(model, \"black\"),\n",
    "                color=language_colors.get(language, \"black\"),  # Use the color for the language\n",
    "                # linestyle=language_styles.get(language, \"-\"),\n",
    "                marker=\"o\",\n",
    "                ax=ax\n",
    "            )\n",
    "\n",
    "            max_y = max(max_y, filtered_df[\"Accuracy\"].max())\n",
    "\n",
    "        # Customize each subplot\n",
    "        ax.set_title(f\"{model} (n_neighbors = {best_n_neighbors})\", fontsize=14)\n",
    "        ax.set_xlabel(\"Layer\", fontsize=12)\n",
    "        ax.set_ylabel(\"Accuracy\", fontsize=12)\n",
    "        ax.legend(title=\"Language\", fontsize=10, loc=\"best\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_n_neighbors_5_accuracy_by_model(dataset_paths, model_colors, languague_styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "def plot_mlp_accuracy(dataset_paths, language_colors, model_styles):\n",
    "    \"\"\"\n",
    "    Plots accuracy for n_neighbors = 5 for each dataset, grouped by language (color) and model (line style).\n",
    "\n",
    "    Args:\n",
    "    - dataset_paths (list): List of file paths to the datasets.\n",
    "    - language_colors (dict): Dictionary mapping languages to colors.\n",
    "    - model_styles (dict): Dictionary mapping models to line styles.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for dataset_path in dataset_paths:\n",
    "        # Extract language and tokenizer from the filename\n",
    "        filename = os.path.basename(dataset_path)\n",
    "        # language = filename.split(\"_\")[5].split(\"-\")[0]  # Extract language (e.g., \"English\", \"Korean\", \"German\")\n",
    "        language = None\n",
    "        for lang in {\"English\", \"Korean\", \"German\"}:\n",
    "            if lang in filename:\n",
    "                language = lang\n",
    "                break\n",
    "        # match = re.search(r'\\b(English|Korean|German)\\b', filename)\n",
    "        # language = match.group(1) if match else None\n",
    "\n",
    "        model = filename.split(\"_\")[4]  # Extract tokenizer (e.g., \"Babel-9B-Chat\")\n",
    "        # model = filename\n",
    "        print(language, model)\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(os.path.join(\"/home/hyujang/multilingual-inner-lexicon\", dataset_path))\n",
    "\n",
    "        # Plot the line for this dataset\n",
    "        sns.lineplot(\n",
    "            data=df,\n",
    "            x=\"Layer\",\n",
    "            y=\"Accuracy\",\n",
    "            label=f\"{language} ({model})\",\n",
    "            color=language_colors.get(language, \"black\"),  # Use the color for the language\n",
    "            linestyle=model_styles.get(model, \"dashdot\"),  # Use the line style for the model\n",
    "            marker=\"o\"\n",
    "        )\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    plt.xlabel(\"Layer\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "    plt.title(\"Accuracy Across Datasets\", fontsize=14)\n",
    "    plt.legend(title=\"Dataset\", fontsize=10, loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_mlp_accuracy(dataset_paths, language_colors, model_styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "def plot_mlp_accuracy_by_language(dataset_paths, language_colors, model_styles, metric=\"Accuracy\"):\n",
    "    \"\"\"\n",
    "    Creates separate subplots for each language, showing accuracy for n_neighbors = 5 for all models.\n",
    "\n",
    "    Args:\n",
    "    - dataset_paths (list): List of file paths to the datasets.\n",
    "    - language_colors (dict): Dictionary mapping languages to colors.\n",
    "    - model_styles (dict): Dictionary mapping models to line styles.\n",
    "    \"\"\"\n",
    "    # Group datasets by language\n",
    "    language_datasets = {\"English\": [], \"Korean\": [], \"German\": []}\n",
    "    for dataset_path in dataset_paths:\n",
    "        filename = os.path.basename(dataset_path)\n",
    "\n",
    "        language = None\n",
    "        for lang in {\"English\", \"Korean\", \"German\"}:\n",
    "            if lang in filename:\n",
    "                language = lang\n",
    "                break\n",
    "        language_datasets[language].append(dataset_path)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(8, 12), sharey=True)\n",
    "    for ax, (language, paths) in zip(axes, language_datasets.items()):\n",
    "        max_y = 0\n",
    "        for dataset_path in paths:\n",
    "            # Extract model from the filename\n",
    "            filename = os.path.basename(dataset_path)\n",
    "            # model = filename.split(\"_\")[3]  # Extract tokenizer (e.g., \"Babel-9B-Chat\")\n",
    "            model = filename.split(\"_\")[4]  # Extract tokenizer (e.g., \"Babel-9B-Chat\")\n",
    "\n",
    "            # Load the dataset\n",
    "            df = pd.read_csv(os.path.join(\"/home/hyujang/multilingual-inner-lexicon\", dataset_path))\n",
    "            \n",
    "            # Plot the line for this dataset\n",
    "            sns.lineplot(\n",
    "                data=df,\n",
    "                x=\"Layer\",\n",
    "                y=f\"{metric}\",\n",
    "                label=model,\n",
    "                color=model_colors.get(model, \"black\"),\n",
    "                # color=language_colors.get(language, \"black\"),  # Use the color for the language\n",
    "                # linestyle=model_styles.get(model, \"-\"),  # Use the line style for the model\n",
    "                marker=\"o\",\n",
    "                ax=ax\n",
    "            )\n",
    "            \n",
    "            max_y = max(max_y, df[f\"{metric}\"].max())\n",
    "\n",
    "        # Customize each subplot\n",
    "        ax.set_title(f\"{language} {metric} (MLP)\", fontsize=14)\n",
    "        ax.set_xlabel(\"Layer\", fontsize=12)\n",
    "        ax.set_ylabel(f\"{metric}\", fontsize=12)\n",
    "        ax.legend(title=\"Model\", fontsize=10, loc=\"best\")\n",
    "        ax.grid(True)\n",
    "        # ax.set_ylim(0, max_y + 0.05)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_mlp_accuracy_by_language(dataset_paths, language_colors, model_styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "def plot_mlp_accuracy_by_model(dataset_paths, language_colors, model_styles, metric=\"Accuracy\"):\n",
    "    \"\"\"\n",
    "    Creates separate subplots for each language, showing accuracy for n_neighbors = 5 for all models.\n",
    "\n",
    "    Args:\n",
    "    - dataset_paths (list): List of file paths to the datasets.\n",
    "    - language_colors (dict): Dictionary mapping languages to colors.\n",
    "    - model_styles (dict): Dictionary mapping models to line styles.\n",
    "    \"\"\"\n",
    "    # Group datasets by language\n",
    "    model_datasets = {\"Babel-9B-Chat\": [], \"gemma-3-12b-it\": [], \"Llama-2-7b-chat-hf\": []}\n",
    "    for dataset_path in dataset_paths:\n",
    "        filename = os.path.basename(dataset_path)\n",
    "        model = filename.split(\"_\")[4]\n",
    "        print(model)\n",
    "        model_datasets[model].append(dataset_path)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(8, 12), sharey=True)\n",
    "    for ax, (model, paths) in zip(axes, model_datasets.items()):\n",
    "        max_y = 0\n",
    "        for dataset_path in paths:\n",
    "            # Extract model from the filename\n",
    "            filename = os.path.basename(dataset_path)\n",
    "            language = None\n",
    "            for lang in {\"English\", \"Korean\", \"German\"}:\n",
    "                if lang in filename:\n",
    "                    language = lang\n",
    "                    break\n",
    "\n",
    "            # Load the dataset\n",
    "            df = pd.read_csv(os.path.join(\"/home/hyujang/multilingual-inner-lexicon\", dataset_path))\n",
    "            # Plot the line for this dataset\n",
    "            sns.lineplot(\n",
    "                data=df,\n",
    "                x=\"Layer\",\n",
    "                y=f\"{metric}\",\n",
    "                label=language,\n",
    "                # color=model_colors.get(model, \"black\"),\n",
    "                color=language_colors.get(language, \"black\"),  # Use the color for the language\n",
    "                # linestyle=model_styles.get(model, \"-\"),  # Use the line style for the model\n",
    "                marker=\"o\",\n",
    "                ax=ax\n",
    "            )\n",
    "            \n",
    "            max_y = max(max_y, df[f\"{metric}\"].max())\n",
    "\n",
    "        # Customize each subplot\n",
    "        ax.set_title(f\"{model} {metric} (MLP)\", fontsize=14)\n",
    "        ax.set_xlabel(\"Layer\", fontsize=12)\n",
    "        ax.set_ylabel(f\"{metric}\", fontsize=12)\n",
    "        ax.legend(title=\"Language\", fontsize=10, loc=\"best\")\n",
    "        ax.grid(True)\n",
    "        # ax.set_ylim(0, max_y + 0.05)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_mlp_accuracy_by_model(dataset_paths, language_colors, model_styles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
