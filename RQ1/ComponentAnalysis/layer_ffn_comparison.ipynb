{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def convert_str_columns_to_lists(df):\n",
    "    for col in df.columns:\n",
    "        # Check if all non-null values look like a list in string form\n",
    "        sample_vals = df[col].dropna().astype(str).head(10)\n",
    "        if sample_vals.apply(lambda x: x.strip().startswith(\"[\") and x.strip().endswith(\"]\")).all():\n",
    "            try:\n",
    "                df[col] = df[col].apply(lambda x: literal_eval(x) if isinstance(x, str) else x)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not convert column '{col}': {e}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## logit lens: plot ffn & hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize(word):\n",
    "    return re.sub(r'\\W+', '', word).lower()  # Remove non-alphanumeric chars and lowercase\n",
    "\n",
    "def get_retrieval_rates(results_df):\n",
    "    token_str_cols = [col for col in results_df.columns if col.endswith(\"_top_token_str\")]\n",
    "    retrieval_rates = [] \n",
    "    layers = []\n",
    "\n",
    "    for col in token_str_cols:\n",
    "        pred_word = results_df[col].apply(lambda x: [normalize(word) for word in x])\n",
    "        original_word = results_df[\"word\"].apply(normalize)\n",
    "        retrieval_match = pred_word.combine(original_word, lambda preds, orig: orig in preds)\n",
    "        retrieval_rate = retrieval_match.mean()\n",
    "        retrieval_rates.append(retrieval_rate)\n",
    "        # Extract layer number from column name, e.g., \"layer_1_top1_token_str\" -> 1\n",
    "        layer_num = int(col.split(\"_\")[1])\n",
    "        layers.append(layer_num)\n",
    "\n",
    "    # Sort by layer number\n",
    "    sorted_indices = sorted(range(len(layers)), key=lambda i: layers[i])\n",
    "    layers = [layers[i] for i in sorted_indices]\n",
    "    retrieval_rates = [retrieval_rates[i] for i in sorted_indices]\n",
    "    \n",
    "    return layers, retrieval_rates\n",
    "\n",
    "def get_cumulative_retrieval_rates(results_df):\n",
    "    layers = sorted([int(col.split(\"_\")[1]) for col in results_df.columns if col.endswith(\"_top_token_str\")])\n",
    "\n",
    "    token_str_cols = [col for col in results_df.columns if col.endswith(\"_top_token_str\")]\n",
    "    token_str_cols = sorted(token_str_cols, key=lambda col: int(col.split(\"_\")[1]))  # Ensure layers are ordered\n",
    "\n",
    "    original_words = results_df[\"word\"].apply(normalize)\n",
    "    num_examples = len(original_words)\n",
    "\n",
    "    cumulative_hits = [False] * num_examples\n",
    "    cumulative_rates = []\n",
    "\n",
    "    for col in token_str_cols:\n",
    "        pred_words = results_df[col].apply(lambda x: [normalize(word) for word in x])\n",
    "        retrieval_match = pred_words.combine(original_words, lambda preds, orig: orig in preds)\n",
    "        # Update cumulative hits\n",
    "        cumulative_hits = [prev or curr for prev, curr in zip(cumulative_hits, retrieval_match)]\n",
    "        cumulative_rate = sum(cumulative_hits) / num_examples\n",
    "        cumulative_rates.append(cumulative_rate)\n",
    "\n",
    "    return layers, cumulative_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Create a grid of subplots (2 rows for languages, 3 columns for models)\n",
    "model_colors = {\n",
    "    \"Babel-9B-Chat\": \"#66c2a5\",\n",
    "    \"gemma-3-12b-it\": \"#fc8d62\",\n",
    "    \"Llama-2-7b-chat-hf\": \"#e78ac3\"\n",
    "}\n",
    "\n",
    "# Define colors for each language\n",
    "language_colors = {\n",
    "    \"English\": \"#1f77b4\",\n",
    "    \"Korean\": \"#ff7f0e\",\n",
    "    \"German\": \"#2ca02c\"\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10), sharex=False, sharey=True)\n",
    "\n",
    "for col_idx, model_name in enumerate(model_colors.keys()):\n",
    "    for row_idx, language in enumerate([\"English\", \"German\"]):\n",
    "        # Load data\n",
    "        layer_df_path = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ1/WordIdentity/single_token_simple_split_{model_name}_{language}_v3.csv\"\n",
    "        ffn_df_path = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ1/ComponentAnalysis/ffn_hidden_states/single_token_simple_split_{model_name}_{language}.csv\"\n",
    "\n",
    "        layer_df = pd.read_csv(layer_df_path)\n",
    "        ffn_df = pd.read_csv(ffn_df_path)\n",
    "\n",
    "        layer_df = convert_str_columns_to_lists(layer_df)\n",
    "        ffn_df = convert_str_columns_to_lists(ffn_df)\n",
    "\n",
    "        layers, retrieval_rates = get_retrieval_rates(layer_df)\n",
    "        ffn_layers, ffn_retrieval_rates = get_retrieval_rates(ffn_df)\n",
    "\n",
    "        layers, cumulative_rates = get_cumulative_retrieval_rates(layer_df)\n",
    "        ffn_layers, ffn_cumulative_rates = get_cumulative_retrieval_rates(ffn_df)\n",
    "\n",
    "        # Plot on the corresponding subplot\n",
    "        ax = axes[row_idx, col_idx]\n",
    "        ax.plot(layers, retrieval_rates, marker='o', label='hidden states', color=\"#adaf3d\", alpha=0.7)\n",
    "        ax.plot(ffn_layers, ffn_retrieval_rates, marker='o', label='FFN output', color=\"#8c59bb\", alpha=0.7)\n",
    "\n",
    "        # Set title and labels\n",
    "        if row_idx == 0:\n",
    "            ax.set_title(model_name, fontsize=14)\n",
    "        if col_idx == 0:\n",
    "            ax.set_ylabel(f\"{language} Retrieval Rate (Top-3)\", fontsize=14)\n",
    "\n",
    "        ax.set_xlabel(\"Layer\", fontsize=12)\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True)\n",
    "\n",
    "        # Set x-axis range dynamically based on layers\n",
    "        ax.set_xlim([min(layers + ffn_layers)-1, max(layers + ffn_layers)+1])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10), sharex=False, sharey=True)\n",
    "\n",
    "for col_idx, model_name in enumerate(model_colors.keys()):\n",
    "    for row_idx, language in enumerate([\"English\", \"German\"]):\n",
    "        # Load data\n",
    "        layer_df_path = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ1/WordIdentity/single_token_simple_split_{model_name}_{language}_v3.csv\"\n",
    "        ffn_df_path = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ1/ComponentAnalysis/ffn_hidden_states/single_token_simple_split_{model_name}_{language}.csv\"\n",
    "\n",
    "        layer_df = pd.read_csv(layer_df_path)\n",
    "        ffn_df = pd.read_csv(ffn_df_path)\n",
    "\n",
    "        layer_df = convert_str_columns_to_lists(layer_df)\n",
    "        ffn_df = convert_str_columns_to_lists(ffn_df)\n",
    "\n",
    "        layers, cumulative_rates = get_cumulative_retrieval_rates(layer_df)\n",
    "        ffn_layers, ffn_cumulative_rates = get_cumulative_retrieval_rates(ffn_df)\n",
    "\n",
    "        # Plot on the corresponding subplot\n",
    "        ax = axes[row_idx, col_idx]\n",
    "        ax.plot(layers, cumulative_rates, marker='o', label='hidden states', color=\"#adaf3d\", alpha=0.7)\n",
    "        ax.plot(ffn_layers, ffn_cumulative_rates, marker='o', label='FFN output', color=\"#8c59bb\", alpha=0.7)\n",
    "\n",
    "        # Set title and labels\n",
    "        if row_idx == 0:\n",
    "            ax.set_title(model_name, fontsize=14)\n",
    "        if col_idx == 0:\n",
    "            ax.set_ylabel(f\"{language} Retrieval Rate (Top-3)\", fontsize=14)\n",
    "\n",
    "        ax.set_xlabel(\"Layer\", fontsize=12)\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True)\n",
    "\n",
    "        # Set x-axis range dynamically based on layers\n",
    "        ax.set_xlim([min(layers + ffn_layers)-1, max(layers + ffn_layers)+1])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(MODEL_NAME, LANGUAGE):\n",
    "    # Load the dataframes\n",
    "    # Adjust the paths as necessary\n",
    "    layer_df = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ1/WordIdentity/single_token_simple_split_{MODEL_NAME}_{LANGUAGE}_v3.csv\"\n",
    "    ffn_df = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ1/ComponentAnalysis/ffn_hidden_states/single_token_simple_split_{MODEL_NAME}_{LANGUAGE}.csv\"\n",
    "\n",
    "    layer_df = pd.read_csv(layer_df)\n",
    "    ffn_df = pd.read_csv(ffn_df)\n",
    "\n",
    "    layer_df = convert_str_columns_to_lists(layer_df)\n",
    "    ffn_df = convert_str_columns_to_lists(ffn_df)\n",
    "\n",
    "    layers, retrieval_rates = get_retrieval_rates(layer_df)\n",
    "    ffn_layers, ffn_retrieval_rates = get_retrieval_rates(ffn_df)\n",
    "\n",
    "    layers, cumulative_rates = get_cumulative_retrieval_rates(layer_df)\n",
    "    ffn_layers, ffn_cumulative_rates = get_cumulative_retrieval_rates(ffn_df)\n",
    "\n",
    "    plot_retrieval_rates(MODEL_NAME, LANGUAGE, layers, retrieval_rates, ffn_layers, ffn_retrieval_rates, retreival_type=\"per_layer\")\n",
    "    plot_retrieval_rates(MODEL_NAME, LANGUAGE, layers, cumulative_rates, ffn_layers, ffn_cumulative_rates, retreival_type=\"cumulative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Tower-Babel/Babel-9B-Chat\"\n",
    "MODEL_NAME = MODEL_NAME.split(\"/\")[-1]\n",
    "LANGUAGE = \"English\"\n",
    "\n",
    "run_analysis(MODEL_NAME, LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Tower-Babel/Babel-9B-Chat\"\n",
    "MODEL_NAME = MODEL_NAME.split(\"/\")[-1]\n",
    "LANGUAGE = \"German\"\n",
    "\n",
    "run_analysis(MODEL_NAME, LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/gemma-3-12b-it\"\n",
    "MODEL_NAME = MODEL_NAME.split(\"/\")[-1]\n",
    "LANGUAGE = \"English\"\n",
    "\n",
    "run_analysis(MODEL_NAME, LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/gemma-3-12b-it\"\n",
    "MODEL_NAME = MODEL_NAME.split(\"/\")[-1]\n",
    "LANGUAGE = \"German\"\n",
    "\n",
    "run_analysis(MODEL_NAME, LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "MODEL_NAME = MODEL_NAME.split(\"/\")[-1]\n",
    "LANGUAGE = \"English\"\n",
    "\n",
    "run_analysis(MODEL_NAME, LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "MODEL_NAME = MODEL_NAME.split(\"/\")[-1]\n",
    "LANGUAGE = \"German\"\n",
    "\n",
    "run_analysis(MODEL_NAME, LANGUAGE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
