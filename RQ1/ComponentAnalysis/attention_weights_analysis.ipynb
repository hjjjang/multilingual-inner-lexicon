{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    \"Tower-Babel/Babel-9B-Chat\",\n",
    "    \"google/gemma-3-12b-it\",\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "]\n",
    "\n",
    "language_list = [\n",
    "    \"English\",\n",
    "    \"German\",\n",
    "    \"Korean\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "version_colors = {\n",
    "    \"\": \"#1f77b4\",  # Blue\n",
    "    \"v2\": \"#ff7f0e\",  # Orange\n",
    "    \"v3\": \"#165a16\",  # Green\n",
    "    \"v4\": \"#d62728\"   # Red\n",
    "}\n",
    "\n",
    "version_linestyles = {\n",
    "    \"\": \":\",\n",
    "    \"v2\": \"--\",\n",
    "    \"v3\": \"-.\",\n",
    "    \"v4\": \":\"\n",
    "}\n",
    "\n",
    "\n",
    "model_colors = {\n",
    "    \"Babel-9B-Chat\": \"#66c2a5\",\n",
    "    \"gemma-3-12b-it\": \"#fc8d62\",\n",
    "    \"Llama-2-7b-chat-hf\": \"#e78ac3\"\n",
    "}\n",
    "\n",
    "# Define colors for each language\n",
    "language_colors = {\n",
    "    \"English\": \"#1f77b4\",\n",
    "    \"Korean\": \"#ff7f0e\",\n",
    "    \"German\": \"#2ca02c\"\n",
    "}\n",
    "\n",
    "# Define line styles for each model\n",
    "model_styles = {\n",
    "    \"Babel-9B-Chat\": \"-\",\n",
    "    \"gemma-3-12b-it\": \"--\",\n",
    "    \"Llama-2-7b-chat-hf\": \":\"\n",
    "}\n",
    "\n",
    "languague_styles = {\n",
    "    \"English\": \"-\",\n",
    "    \"Korean\": \"--\",\n",
    "    \"German\": \":\"\n",
    "}\n",
    "\n",
    "type_colors = {\n",
    "    \"v1\": \"#557fb1\",\n",
    "    \"v2\": \"#ee6e44\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Set your directory path here\n",
    "directory_path = \"/home/hyujang/multilingual-inner-lexicon/output/RQ1/ComponentAnalysis/attention_weights2\"\n",
    "\n",
    "# Find all CSV files ending with \"_2token.csv\"\n",
    "# csv_files = glob.glob(os.path.join(directory_path, \"*_2token.csv\"))\n",
    "csv_files = glob.glob(os.path.join(directory_path, \"*token.csv\"))\n",
    "\n",
    "\n",
    "# Load and concatenate all DataFrames\n",
    "# df_list = [pd.read_csv(file) for file in csv_files]\n",
    "min_length = 10000  # Set your minimum length here\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"File: {file}, Length: {df.shape[0]}, max_context_length: {df['context'].apply(len).max()}\")\n",
    "    if df.shape[0] < min_length:   \n",
    "        min_length = df.shape[0]\n",
    "\n",
    "print(f\"Minimum length across all files: {min_length}\")\n",
    "\n",
    "# filter the \n",
    "df_dict = {}\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.sample(n=min_length, random_state=2025)  # Sample min_length rows\n",
    "    df_dict[file.split('/')[-1]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = \"/home/hyujang/multilingual-inner-lexicon/output/RQ1/ComponentAnalysis/attention_weights2\"\n",
    "\n",
    "# Create subplots with independent columns\n",
    "fig, axes = plt.subplots(\n",
    "    len(language_list),\n",
    "    len(model_list),\n",
    "    figsize=(15, 10),\n",
    "    sharex='col',   # âœ… share only within columns\n",
    "    sharey=True     # still share y across all subplots\n",
    ")\n",
    "\n",
    "# Ensure axes is 2D even if lists are length 1\n",
    "if len(language_list) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "if len(model_list) == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "# Iterate over each model and language pair\n",
    "for col_idx, model in enumerate(model_list):\n",
    "    for row_idx, language in enumerate(language_list):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "\n",
    "        # Find the corresponding files for _2token and _single-token\n",
    "        file_2token = glob.glob(os.path.join(directory_path, f\"{model.split('/')[-1]}_{language}_2token.csv\"))\n",
    "        file_single_token = glob.glob(os.path.join(directory_path, f\"{model.split('/')[-1]}_{language}_1token.csv\"))\n",
    "\n",
    "        if not file_2token or not file_single_token:\n",
    "            ax.set_title(f\"{language}\\nFile not found\", fontsize=8)\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        # Load the DataFrames\n",
    "        df_2token = pd.read_csv(file_2token[0])\n",
    "        df_single_token = pd.read_csv(file_single_token[0])\n",
    "\n",
    "        # Extract layer-wise attention columns\n",
    "        layer_columns = [col for col in df_2token.columns if col.startswith(\"layer_\")]\n",
    "\n",
    "        # Compute the average attention scores for each layer\n",
    "        avg_attention_2token = df_2token[layer_columns].mean()\n",
    "        avg_attention_single_token = df_single_token[layer_columns].mean()\n",
    "\n",
    "        # Plot the attention scores\n",
    "        ax.plot(\n",
    "            range(1, len(avg_attention_2token) + 1),\n",
    "            avg_attention_2token,\n",
    "            marker='o',\n",
    "            linestyle='--',\n",
    "            # color='b',\n",
    "            color=\"#557fb1\",\n",
    "            label=f'two-token words (n={len(df_2token)})'\n",
    "        )\n",
    "        ax.plot(\n",
    "            range(1, len(avg_attention_single_token) + 1),\n",
    "            avg_attention_single_token,\n",
    "            marker='o',\n",
    "            linestyle='--',\n",
    "            color='#ee6e44',\n",
    "            label=f'single-token words (n={len(df_single_token)})'\n",
    "        )\n",
    "\n",
    "        # Customize the subplot\n",
    "        if row_idx == 0:\n",
    "            ax.set_title(f\"{model.split('/')[-1]}\", fontsize=22)\n",
    "        if col_idx == 0:\n",
    "            ax.set_ylabel(f\"{language}\\nAvg. Attention Weight\", fontsize=16)\n",
    "        \n",
    "        ax.set_xlabel(\"Layer\", fontsize=16)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        ax.legend(fontsize=14)\n",
    "        ax.grid(True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each dataset\n",
    "for dataset_name, df in df_dict.items():\n",
    "    # Extract layer-wise attention columns\n",
    "    layer_columns = [col for col in df.columns if col.startswith(\"layer_\")]\n",
    "\n",
    "    # Ensure the second layer exists\n",
    "    if \"layer_2_attn\" not in layer_columns:\n",
    "        print(f\"Second layer not found in {dataset_name}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Get the second layer's attention weight\n",
    "    second_layer_attn = df[\"layer_2_attn\"]\n",
    "\n",
    "    # Calculate the average difference with other layers\n",
    "    for col in layer_columns:\n",
    "        if col != \"layer_2_attn\":\n",
    "            avg_diff = (df[col] - second_layer_attn).mean()\n",
    "            results.append({\n",
    "                \"Dataset\": dataset_name,\n",
    "                \"Layer\": col,\n",
    "                \"Average Difference\": avg_diff\n",
    "            })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "THESIS",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
