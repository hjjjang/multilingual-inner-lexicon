{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## visualize all 36 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def normalize(text, lang=\"German\"):\n",
    "    \"\"\" Normalize text: lowercasing, unicode normalize, replace ß with ss, remove accents \"\"\"\n",
    "    text = text.lower().strip()\n",
    "    text = text.replace(\"ß\", \"ss\")\n",
    "    text = text.replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\")\n",
    "    # Remove accents\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = \"\".join(c for c in text if not unicodedata.combining(c))\n",
    "    return text\n",
    "\n",
    "def is_match(output, targets, lang=\"German\"):\n",
    "    norm_output = normalize(output, lang)\n",
    "    for target in targets:\n",
    "        norm_target = normalize(target, lang)\n",
    "        # Exact match or substring match\n",
    "        if norm_target in norm_output or norm_output in norm_target:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "\n",
    "# Define models, languages, and prompt versions\n",
    "models = [\"Tower-Babel/Babel-9B-Chat\", \"google/gemma-3-12b-it\", \"meta-llama/Llama-2-7b-chat-hf\"]\n",
    "language_pairs = [(\"English\", \"Korean\"), (\"Korean\", \"English\"), (\"English\", \"German\"), (\"German\", \"English\"), (\"German\", \"Korean\"), (\"Korean\", \"German\")]\n",
    "\n",
    "# Define colors and line styles for visualization\n",
    "pair_colors = {\n",
    "    (\"English\", \"Korean\"): \"#1f77b4\",  # Blue\n",
    "    (\"Korean\", \"English\"): \"#ff7f0e\",  # Orange\n",
    "    (\"English\", \"German\"): \"#2ca02c\",  # Green\n",
    "    (\"German\", \"English\"): \"#d62728\",  # Red\n",
    "    (\"German\", \"Korean\"): \"#9467bd\",  # Purple\n",
    "    (\"Korean\", \"German\"): \"#8c564b\",  # Brown\n",
    "}\n",
    "version_colors = {\n",
    "    0 : \"#1f77b4\",  # Blue\n",
    "    1: \"#ff7f0e\",  # Orange\n",
    "    2: \"#2ca02c\",  # Green\n",
    "    3: \"#8c564b\",  # Brown\n",
    "}\n",
    "\n",
    "prompt_styles = {\n",
    "    \"EnglishPrompt\": \"--\",\n",
    "    \"KoreanPrompt\": \"-\",\n",
    "    \"GermanPrompt\": \":\"\n",
    "}\n",
    "\n",
    "lang_abbr = {\n",
    "    \"English\": \"En\",\n",
    "    \"Korean\": \"Ko\",\n",
    "    \"German\": \"De\"\n",
    "}\n",
    "promptversion_abbr = {\n",
    "    \"EnglishPrompt\": \"En\",\n",
    "    \"KoreanPrompt\": \"Ko\",\n",
    "    \"GermanPrompt\": \"De\"\n",
    "}\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(models), len(language_pairs) // 2, figsize=(20, 15), sharex=True, sharey=True)\n",
    "# fig.suptitle(\"PatchScope Retrieval Rate per Layer (Models & Language Pairs)\", fontsize=20)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model_short = model.split(\"/\")[-1]\n",
    "    for j, pair_group in enumerate([language_pairs[:2], language_pairs[2:4], language_pairs[4:]]):  # Group pairs into subplots\n",
    "        ax = axes[j, i]\n",
    "        for src, tgt in pair_group:\n",
    "            prompt_versions = [f\"{src}Prompt\", f\"{tgt}Prompt\"]\n",
    "            for prompt_version in prompt_versions:\n",
    "                try:\n",
    "                    # Load dataset\n",
    "                    data_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/data/RQ2/MUSE/{src}_{tgt}_1000.csv\")\n",
    "                    data_df[tgt] = data_df[tgt].apply(literal_eval)\n",
    "                    data_dict = dict(zip(data_df[src], data_df[tgt]))\n",
    "\n",
    "                    # Load output\n",
    "                    output_path = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/num_token_20/{model_short}_{src}_to_{tgt}_{prompt_version}_withOriginalCode.csv\"\n",
    "                    output_df = pd.read_csv(output_path)\n",
    "                    output_df[\"patchscope_result\"] = output_df[\"patchscope_result\"].str.replace(\"\\n\", \" \")\n",
    "\n",
    "                    # Compute retrieval rate\n",
    "                    output_df['retrieved'] = output_df.apply(\n",
    "                        lambda row: any(value in str(row['patchscope_result']) for value in data_dict.get(row['word'], [])),\n",
    "                        axis=1\n",
    "                    )\n",
    "                    retrieval_rate_by_layer = output_df.groupby('layer')['retrieved'].mean()\n",
    "\n",
    "                    # Plot retrieval rate\n",
    "                    ax.plot(\n",
    "                        retrieval_rate_by_layer.index,\n",
    "                        retrieval_rate_by_layer.values,\n",
    "                        marker='o',\n",
    "                        label=f\"{lang_abbr[src]}→{lang_abbr[tgt]} ({promptversion_abbr[prompt_version]})\",\n",
    "                        # color = \n",
    "                        # color=pair_colors.get((src, tgt), \"black\"),\n",
    "                        # linestyle=prompt_styles.get(prompt_version, \"-\"),\n",
    "                        alpha=0.7\n",
    "                    )\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"Data file for {model_short} ({src}-{tgt}, {prompt_version}) not found. Skipping...\")\n",
    "\n",
    "        # Set subplot title and labels\n",
    "        ax.set_title(f\"{model_short}: {pair_group[0][0]}↔{pair_group[0][1]}\", fontsize=20)\n",
    "        if j == len(models) - 1:\n",
    "            ax.set_xlabel(\"Layer\", fontsize=16)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Translation Success Rate\", fontsize=16)\n",
    "        ax.grid(True)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        ax.legend(title=\"Lang Pair (Prompt Lang)\", fontsize=14)\n",
    "\n",
    "# Adjust layout and show plot\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout for title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "\n",
    "# Define models, languages, and prompt versions\n",
    "models = [\"Tower-Babel/Babel-9B-Chat\", \"google/gemma-3-12b-it\", \"meta-llama/Llama-2-7b-chat-hf\"]\n",
    "languages = [\"English\", \"Korean\", \"German\"]\n",
    "language_pairs = [(src, tgt) for src in languages for tgt in languages if src != tgt]\n",
    "\n",
    "# Define colors and line styles for visualization\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(models), len(language_pairs), figsize=(25, 15), sharex=True, sharey=True)\n",
    "fig.suptitle(\"PatchScope Retrieval Rate per Layer (Models & Language Pairs)\", fontsize=20)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model_short = model.split(\"/\")[-1]\n",
    "    for j, (src, tgt) in enumerate(language_pairs):\n",
    "        ax = axes[i, j]\n",
    "        prompt_versions = [f\"{src}Prompt\", f\"{tgt}Prompt\"]\n",
    "        for prompt_version in prompt_versions:\n",
    "            try:\n",
    "                # Load dataset\n",
    "                data_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/data/RQ2/MUSE/{src}_{tgt}_1000.csv\")\n",
    "                data_df[tgt] = data_df[tgt].apply(literal_eval)\n",
    "                data_dict = dict(zip(data_df[src], data_df[tgt]))\n",
    "\n",
    "                # Load output\n",
    "                output_path = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/num_token_20/{model_short}_{src}_to_{tgt}_{prompt_version}_withOriginalCode.csv\"\n",
    "                output_df = pd.read_csv(output_path)\n",
    "                output_df[\"patchscope_result\"] = output_df[\"patchscope_result\"].str.replace(\"\\n\", \" \")\n",
    "\n",
    "                # Compute retrieval rate\n",
    "\n",
    "                # Apply matching\n",
    "                output_df['retrieved'] = output_df.apply(\n",
    "                    lambda row: is_match(row['patchscope_result'], data_dict.get(row['word'], []), lang=tgt),\n",
    "                    axis=1\n",
    "                )\n",
    "                \n",
    "                retrieval_rate_by_layer = output_df.groupby('layer')['retrieved'].mean()\n",
    "\n",
    "                # Plot retrieval rate\n",
    "                ax.plot(\n",
    "                    retrieval_rate_by_layer.index,\n",
    "                    retrieval_rate_by_layer.values,\n",
    "                    marker='o',\n",
    "                    label=f\"{prompt_version}\",\n",
    "                    alpha=0.5,\n",
    "                    # linestyle=prompt_styles[prompt_version]\n",
    "                )\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Data file for {model_short} ({src}-{tgt}, {prompt_version}) not found. Skipping...\")\n",
    "\n",
    "        # Set subplot title and labels\n",
    "        ax.set_title(f\"{model_short}: {src}-{tgt}\")\n",
    "        if i == len(models) - 1:\n",
    "            ax.set_xlabel(\"Layer\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"Translation Success Rate\")\n",
    "        ax.grid(True)\n",
    "        ax.legend(title=\"Prompt Version\")\n",
    "\n",
    "# Adjust layout and show plot\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout for title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\"Tower-Babel/Babel-9B-Chat\", \"google/gemma-3-12b-it\", \"meta-llama/Llama-2-7b-chat-hf\"]\n",
    "\n",
    "model_short = \"google/gemma-3-12b-it\".split(\"/\")[-1]\n",
    "src = \"Korean\"\n",
    "tgt = \"English\"\n",
    "prompt_version = \"EnglishPrompt\"\n",
    "\n",
    "data_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/data/RQ2/MUSE/{src}_{tgt}_1000.csv\")\n",
    "data_df[tgt] = data_df[tgt].apply(literal_eval)\n",
    "data_dict = dict(zip(data_df[src], data_df[tgt]))\n",
    "\n",
    "# Load output\n",
    "output_path = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/num_token_20/{model_short}_{src}_to_{tgt}_{prompt_version}_withOriginalCode.csv\"\n",
    "output_df = pd.read_csv(output_path)\n",
    "output_df[\"patchscope_result\"] = output_df[\"patchscope_result\"].str.replace(\"\\n\", \" \")\n",
    "\n",
    "# Compute retrieval rate\n",
    "output_df['retrieved'] = output_df.apply(\n",
    "    lambda row: is_match(row['patchscope_result'], data_dict.get(row['word'], []), lang=tgt),\n",
    "    axis=1\n",
    ")\n",
    "output_df[\"target\"] = output_df[\"word\"].apply(lambda x: data_dict.get(x, []))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df[\"patchscope_result\"].value_counts().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_version = \"KoreanPrompt\"\n",
    "output_path = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/num_token_20/{model_short}_{src}_to_{tgt}_{prompt_version}_withOriginalCode.csv\"\n",
    "output_df_2 = pd.read_csv(output_path)\n",
    "output_df_2[\"patchscope_result\"] = output_df_2[\"patchscope_result\"].str.replace(\"\\n\", \" \")\n",
    "\n",
    "output_df_2['retrieved'] = output_df_2.apply(\n",
    "    lambda row: is_match(row['patchscope_result'], data_dict.get(row['word'], []), lang=tgt),\n",
    "    axis=1\n",
    ")\n",
    "output_df_2[\"target\"] = output_df_2[\"word\"].apply(lambda x: data_dict.get(x, []))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_2[\"patchscope_result\"].value_counts().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([output_df, output_df_2], axis=1).to_excel(\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/num_token_20/not_retrieved.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df[~output_df[\"retrieved\"]].to_csv(\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/num_token_20/not_retrieved.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "\n",
    "# Define models, languages, and prompt versions\n",
    "models = [\"Tower-Babel/Babel-9B-Chat\", \"google/gemma-3-12b-it\", \"meta-llama/Llama-2-7b-chat-hf\"]\n",
    "languages = [\"English\", \"Korean\", \"German\"]\n",
    "language_pairs = [(src, tgt) for src in languages for tgt in languages if src != tgt]\n",
    "\n",
    "# Define colors and line styles for visualization\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(models), len(language_pairs), figsize=(25, 15), sharex=True, sharey=True)\n",
    "fig.suptitle(\"PatchScope Retrieval Rate per Layer (Models & Language Pairs)\", fontsize=20)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model_short = model.split(\"/\")[-1]\n",
    "    for j, (src, tgt) in enumerate(language_pairs):\n",
    "        ax = axes[i, j]\n",
    "        prompt_versions = [f\"{src}Prompt\", f\"{tgt}Prompt\"]\n",
    "        for prompt_version in prompt_versions:\n",
    "            # Load dataset\n",
    "            data_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/data/RQ2/MUSE/{src}_{tgt}_1000.csv\")\n",
    "            data_df[tgt] = data_df[tgt].apply(literal_eval)\n",
    "            data_dict = dict(zip(data_df[src], data_df[tgt]))\n",
    "\n",
    "            # Load output\n",
    "            output_path = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/num_token_20/{model_short}_{src}_to_{tgt}_{prompt_version}_withOriginalCode.csv\"\n",
    "            output_df = pd.read_csv(output_path)\n",
    "            output_df[\"patchscope_result\"] = output_df[\"patchscope_result\"].str.replace(\"\\n\", \" \")\n",
    "\n",
    "            # Compute retrieval rate\n",
    "\n",
    "            # Apply matching\n",
    "            output_df['retrieved'] = output_df.apply(\n",
    "                lambda row: is_match(row['patchscope_result'], data_dict.get(row['word'], []), lang=tgt),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            print(f\"Processing {model_short} ({src}-{tgt}, {prompt_version})...\")\n",
    "            # print(output_df[\"patchscope_result\"].value_counts().sort_values(ascending=False).head(10))\n",
    "            \n",
    "            value_counts = output_df[\"patchscope_result\"].value_counts()\n",
    "\n",
    "            n = 100\n",
    "            count_over_n = (value_counts > n).sum()\n",
    "            print(f\"→ {count_over_n} unique answers occurred more than {n} times.\")\n",
    "            \n",
    "            total = len(output_df)\n",
    "            unique = output_df[\"patchscope_result\"].nunique()\n",
    "            duplicate_ratio = 1 - unique / total\n",
    "            print(f\"→ {duplicate_ratio:.2%} of outputs are duplicates.\")\n",
    "\n",
    "            top_k = 10\n",
    "            top_k_total = value_counts.head(top_k).sum()\n",
    "            print(f\"→ Top {top_k} answers account for {top_k_total / total:.2%} of all outputs.\")\n",
    "\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Define models, languages, and prompt versions\n",
    "models = [\"Tower-Babel/Babel-9B-Chat\", \"google/gemma-3-12b-it\", \"meta-llama/Llama-2-7b-chat-hf\"]\n",
    "languages = [\"English\", \"Korean\", \"German\"]\n",
    "language_pairs = [(src, tgt) for src in languages for tgt in languages if src != tgt]\n",
    "\n",
    "# Summary storage\n",
    "summary_rows = []\n",
    "TOP_K = 10\n",
    "THRESHOLD = 100\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(models), len(language_pairs), figsize=(25, 15), sharex=True, sharey=True)\n",
    "fig.suptitle(\"PatchScope Retrieval Rate per Layer (Models & Language Pairs)\", fontsize=20)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model_short = model.split(\"/\")[-1]\n",
    "    for j, (src, tgt) in enumerate(language_pairs):\n",
    "        ax = axes[i, j]\n",
    "        prompt_versions = [f\"{src}Prompt\", f\"{tgt}Prompt\"]\n",
    "\n",
    "        for prompt_version in prompt_versions:\n",
    "            try:\n",
    "                # Load dataset\n",
    "                data_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/data/RQ2/MUSE/{src}_{tgt}_1000.csv\")\n",
    "                data_df[tgt] = data_df[tgt].apply(literal_eval)\n",
    "                data_dict = dict(zip(data_df[src], data_df[tgt]))\n",
    "\n",
    "                # Load model output\n",
    "                output_path = f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/num_token_20/{model_short}_{src}_to_{tgt}_{prompt_version}_withOriginalCode.csv\"\n",
    "                output_df = pd.read_csv(output_path)\n",
    "                output_df[\"patchscope_result\"] = output_df[\"patchscope_result\"].str.replace(\"\\n\", \" \")\n",
    "\n",
    "                # Compute repetition statistics\n",
    "                value_counts = output_df[\"patchscope_result\"].value_counts()\n",
    "                total = len(output_df)\n",
    "                unique = value_counts.count()\n",
    "                duplicate_ratio = 1 - unique / total\n",
    "                count_over_threshold = (value_counts > THRESHOLD).sum()\n",
    "                top_k_total = value_counts.head(TOP_K).sum()\n",
    "                top_k_ratio = top_k_total / total\n",
    "                probabilities = value_counts / value_counts.sum()\n",
    "                ent = entropy(probabilities, base=2)\n",
    "\n",
    "                summary_rows.append({\n",
    "                    \"Model\": model_short,\n",
    "                    \"Source\": src,\n",
    "                    \"Target\": tgt,\n",
    "                    \"Prompt\": prompt_version,\n",
    "                    \"Total Outputs\": total,\n",
    "                    \"Unique Outputs\": unique,\n",
    "                    \"Duplicate Ratio\": f\"{duplicate_ratio:.2%}\",\n",
    "                    f\"# Outputs >{THRESHOLD}\": count_over_threshold,\n",
    "                    f\"Top {TOP_K} %\": f\"{top_k_ratio:.2%}\",\n",
    "                    \"Entropy (bits)\": round(ent, 2)\n",
    "                })\n",
    "\n",
    "                # Optional: dummy retrieval check if needed\n",
    "                output_df['retrieved'] = False  # or apply your match logic here\n",
    "\n",
    "                # Plot retrieval rate if retrieved column is used\n",
    "                if 'layer' in output_df.columns:\n",
    "                    retrieval_rate_by_layer = output_df.groupby('layer')['retrieved'].mean()\n",
    "                    ax.plot(\n",
    "                        retrieval_rate_by_layer.index,\n",
    "                        retrieval_rate_by_layer.values,\n",
    "                        marker='o',\n",
    "                        label=f\"{prompt_version}\",\n",
    "                        alpha=0.5,\n",
    "                    )\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found for {model_short} ({src}-{tgt}, {prompt_version})\")\n",
    "                continue\n",
    "\n",
    "        ax.set_title(f\"{model_short}: {src}-{tgt}\")\n",
    "        if i == len(models) - 1:\n",
    "            ax.set_xlabel(\"Layer\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"Translation Success Rate\")\n",
    "        ax.grid(True)\n",
    "        ax.legend(title=\"Prompt Version\")\n",
    "\n",
    "# Plot formatting\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Create and save summary table\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(by=[\"Model\", \"Source\", \"Target\", \"Prompt\"])\n",
    "print(summary_df)\n",
    "\n",
    "# Save to CSV\n",
    "# summary_df.to_csv(\"output_repetition_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv(\"output_repetition_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## visualize all for a single language pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "\n",
    "SOURCE_LANGUAGE = \"Korean\"\n",
    "TARGET_LANGUAGE = \"English\"\n",
    "\n",
    "# Define models and prompt versions\n",
    "models = [\"Tower-Babel/Babel-9B-Chat\", \"google/gemma-3-12b-it\", \"meta-llama/Llama-2-7b-chat-hf\"]\n",
    "prompt_versions = [f\"{SOURCE_LANGUAGE}Prompt\", f\"{TARGET_LANGUAGE}Prompt\"]\n",
    "\n",
    "# Define colors and line styles for visualization\n",
    "model_colors = {\n",
    "    \"Babel-9B-Chat\": \"#66c2a5\",\n",
    "    \"gemma-3-12b-it\": \"#fc8d62\",\n",
    "    \"Llama-2-7b-chat-hf\": \"#e78ac3\"\n",
    "}\n",
    "prompt_styles = {\n",
    "    f\"{SOURCE_LANGUAGE}Prompt\": \"--\",\n",
    "    f\"{TARGET_LANGUAGE}Prompt\": \"-\"\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Iterate through models and prompt versions\n",
    "for model in models:\n",
    "    model_short = model.split(\"/\")[-1]\n",
    "    for prompt_version in prompt_versions:\n",
    "        try:\n",
    "            data_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/data/RQ2/MUSE/{SOURCE_LANGUAGE}_{TARGET_LANGUAGE}_1000.csv\")\n",
    "            data_df[f\"{TARGET_LANGUAGE}\"] = data_df[f\"{TARGET_LANGUAGE}\"].apply(literal_eval)\n",
    "            data_dict = dict(zip(data_df[f\"{SOURCE_LANGUAGE}\"], data_df[f\"{TARGET_LANGUAGE}\"]))\n",
    "            \n",
    "            output_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/{model_short}_{SOURCE_LANGUAGE}_to_{TARGET_LANGUAGE}_{prompt_version}.csv\")\n",
    "            output_df[\"patchscope_result\"] = output_df[\"patchscope_result\"].str.replace(\"\\n\",\" \")\n",
    "            \n",
    "            output_df['retrieved'] = output_df.apply(\n",
    "                lambda row: any(value in str(row['patchscope_result']) for value in data_dict.get(row['word'], [])),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            retrieval_rate_by_layer = output_df.groupby('layer')['retrieved'].mean()\n",
    "            \n",
    "            # Plot retrieval rate\n",
    "            plt.plot(\n",
    "                retrieval_rate_by_layer.index,\n",
    "                retrieval_rate_by_layer.values,\n",
    "                marker='o',\n",
    "                label=f\"{model_short} ({prompt_version})\",\n",
    "                color=model_colors.get(model_short, \"black\"),\n",
    "                linestyle=prompt_styles.get(prompt_version, \"-\")\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Data file for {model_short} with {prompt_version} not found. Skipping...\")\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Translation Success Rate\")\n",
    "plt.title(\"PatchScope Retrieval Rate per Layer (Models & Prompt Versions)\")\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"Model & Prompt Version\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## visualize a single result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df['retrieved'] = output_df.apply(\n",
    "    lambda row: any(value in str(row['patchscope_result']) for value in data_dict.get(row['word'], [])),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/{MODEL_NAME}_{SOURCE_LANGUAGE}_to_{TARGET_LANGUAGE}_KoreanPrompt_withOriginalCode.csv\")\n",
    "output_df[\"patchscope_result\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df[output_df[\"retrieved\"]][\"patchscope_result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "SOURCE_LANGUAGE = \"English\"\n",
    "TARGET_LANGUAGE = \"German\"\n",
    "MODEL_NAME = \"google/gemma-3-12b-it\"\n",
    "# MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# MODEL_NAME = \"Tower-Babel/Babel-9B-Chat\"\n",
    "MODEL_NAME = MODEL_NAME.split(\"/\")[-1]  # Extract model name for output file\n",
    "\n",
    "data_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/data/RQ2/MUSE/{SOURCE_LANGUAGE}_{TARGET_LANGUAGE}_1000.csv\")\n",
    "data_df[f\"{TARGET_LANGUAGE}\"] = data_df[f\"{TARGET_LANGUAGE}\"].apply(literal_eval)\n",
    "output_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/{MODEL_NAME}_{SOURCE_LANGUAGE}_to_{TARGET_LANGUAGE}_EnglishPrompt_withOriginalCode.csv\")\n",
    "output_df[\"patchscope_result\"] = output_df[\"patchscope_result\"].str.replace(\"\\n\",\" \")\n",
    "data_dict = dict(zip(data_df[f\"{SOURCE_LANGUAGE}\"], data_df[f\"{TARGET_LANGUAGE}\"]))\n",
    "output_df['retrieved'] = output_df.apply(\n",
    "    lambda row: any(value in str(row['patchscope_result']) for value in data_dict.get(row['word'], [])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "retrieval_rate = output_df['retrieved'].mean()\n",
    "\n",
    "# print(output_df[output_df['retrieved']][\"word\"].value_counts())\n",
    "print(output_df[output_df['retrieved']][\"word\"].unique())\n",
    "en_prompt_true_list = output_df[output_df['retrieved']][\"word\"].unique()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Group by layer and compute retrieval rate\n",
    "retrieval_rate_by_layer = output_df.groupby('layer')['retrieved'].mean()\n",
    "\n",
    "# Plot the retrieval rate\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(retrieval_rate_by_layer.index, retrieval_rate_by_layer.values, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Translation Success Rate\")\n",
    "plt.title(f\"PatchScope Retrieval Rate per Layer ({MODEL_NAME}, {SOURCE_LANGUAGE} to {TARGET_LANGUAGE})\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "SOURCE_LANGUAGE = \"Korean\"\n",
    "TARGET_LANGUAGE = \"English\"\n",
    "MODEL_NAME = \"google/gemma-3-12b-it\"\n",
    "# MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# MODEL_NAME = \"Tower-Babel/Babel-9B-Chat\"\n",
    "MODEL_NAME = MODEL_NAME.split(\"/\")[-1]  # Extract model name for output file\n",
    "\n",
    "data_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/data/RQ2/MUSE/{SOURCE_LANGUAGE}_{TARGET_LANGUAGE}_1000.csv\")\n",
    "data_df[f\"{TARGET_LANGUAGE}\"] = data_df[f\"{TARGET_LANGUAGE}\"].apply(literal_eval)\n",
    "output_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/{MODEL_NAME}_{SOURCE_LANGUAGE}_to_{TARGET_LANGUAGE}_KoreanPrompt_withOriginalCode_v2.csv\")\n",
    "output_df[\"patchscope_result\"] = output_df[\"patchscope_result\"].str.replace(\"\\n\",\" \")\n",
    "data_dict = dict(zip(data_df[f\"{SOURCE_LANGUAGE}\"], data_df[f\"{TARGET_LANGUAGE}\"]))\n",
    "output_df['retrieved'] = output_df.apply(\n",
    "    lambda row: any(value in str(row['patchscope_result']) for value in data_dict.get(row['word'], [])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "retrieval_rate = output_df['retrieved'].mean()\n",
    "\n",
    "# print(output_df[output_df['retrieved']][\"word\"].value_counts())\n",
    "print(output_df[output_df['retrieved']][\"word\"].unique())\n",
    "en_prompt_true_list = output_df[output_df['retrieved']][\"word\"].unique()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Group by layer and compute retrieval rate\n",
    "retrieval_rate_by_layer = output_df.groupby('layer')['retrieved'].mean()\n",
    "\n",
    "# Plot the retrieval rate\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(retrieval_rate_by_layer.index, retrieval_rate_by_layer.values, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Translation Success Rate\")\n",
    "plt.title(f\"PatchScope Retrieval Rate per Layer ({MODEL_NAME}, {SOURCE_LANGUAGE} to {TARGET_LANGUAGE})\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## visualize specific files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gemma-3-12b-it\"\n",
    "\n",
    "output_paths = [f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/{MODEL_NAME}_{SOURCE_LANGUAGE}_to_{TARGET_LANGUAGE}_KoreanPrompt.csv\", \n",
    "                f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/{MODEL_NAME}_{SOURCE_LANGUAGE}_to_{TARGET_LANGUAGE}_KoreanPrompt_v2.csv\",\n",
    "                # f\"/home/hyujang/multilingual-inner-lexicon/output/RQ2/PatchScope/{MODEL_NAME}_{SOURCE_LANGUAGE}_to_{TARGET_LANGUAGE}_v3.csv\"\n",
    "                ]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for output_path in output_paths:\n",
    "    data_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/data/RQ2/MUSE/{SOURCE_LANGUAGE}-{TARGET_LANGUAGE}_1000.csv\")\n",
    "    data_df[f\"{TARGET_LANGUAGE}\"] = data_df[f\"{TARGET_LANGUAGE}\"].apply(literal_eval)\n",
    "    output_df = pd.read_csv(output_path)\n",
    "    output_df[\"patchscope_result\"] = output_df[\"patchscope_result\"].str.replace(\"\\n\",\" \")\n",
    "    data_dict = dict(zip(data_df[f\"{SOURCE_LANGUAGE}\"], data_df[f\"{TARGET_LANGUAGE}\"]))\n",
    "    output_df['retrieved'] = output_df.apply(\n",
    "        lambda row: any(value in str(row['patchscope_result']) for value in data_dict.get(row['word'], [])),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    retrieval_rate_by_layer = output_df.groupby('layer')['retrieved'].mean()\n",
    "    # print(f\"{output_path.split('/')[-1]}\")\n",
    "    plt.plot(\n",
    "    retrieval_rate_by_layer.index,\n",
    "    retrieval_rate_by_layer.values,\n",
    "    marker='o',\n",
    "    # label=\"hi\"\n",
    "    label=f\"{output_path.split('/')[-1].replace(\".csv\",\"\")}\",  # Use the file name as label\n",
    "    # color=language_colors.get(lang, \"black\"),  # Use the color for the language\n",
    "    # linestyle=model_styles.get(model_short, \"dashdot\"),  # Use the line style for the model\n",
    "        )\n",
    "\n",
    "\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Translation Success Rate\")\n",
    "plt.title(f\"PatchScope Retrieval Rate per Layer ({MODEL_NAME}, {SOURCE_LANGUAGE} to {TARGET_LANGUAGE})\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
