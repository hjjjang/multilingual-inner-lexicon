{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Word Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "# sys.path.append(os.path.abspath(\"../RQ1/WordNonword/\"))\n",
    "# from classification import WordNonwordClassifier\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from utils import extract_token_hidden_states\n",
    "\n",
    "def prepare_dataset(SOURCE_LANGUAGE, TARGET_LANGUAGE):\n",
    "    data_df = pd.read_csv(f\"/home/hyujang/multilingual-inner-lexicon/data/RQ2/MUSE/{SOURCE_LANGUAGE}_{TARGET_LANGUAGE}_1000.csv\")\n",
    "    data_df[TARGET_LANGUAGE] = data_df[TARGET_LANGUAGE].apply(literal_eval)\n",
    "    return data_df\n",
    "\n",
    "def compute_alignment(SOURCE_LANGUAGE, TARGET_LANGUAGE, source_words_list, target_words_list, hidden_source, hidden_target, dataset, top_k=100):\n",
    "    results = {}\n",
    "    for layer in hidden_source:\n",
    "        source_vecs = hidden_source[layer]  # shape: (N, D)\n",
    "        target_vecs = hidden_target[layer]  # shape: (M, D)\n",
    "\n",
    "        # Normalize to unit vectors for cosine similarity\n",
    "        source_norm = F.normalize(source_vecs, p=2, dim=1)  # (N, D)\n",
    "        target_norm = F.normalize(target_vecs, p=2, dim=1)  # (M, D)\n",
    "\n",
    "        # Compute cosine similarity: (N x D) @ (D x M) = (N x M)\n",
    "        sim_matrix = source_norm @ target_norm.T  # (N, M)\n",
    "\n",
    "        # Get top-k most similar target words for each source word\n",
    "        topk_values, topk_indices = torch.topk(sim_matrix, k=top_k, dim=1)  # (N, top_k)\n",
    "\n",
    "        # Check if the most similar word is in the translated list\n",
    "        relevance_lists = []\n",
    "        for i, top_indices in enumerate(topk_indices):\n",
    "            source_word = source_words_list[i]\n",
    "            # Get correct translations (handle both list and string cases)\n",
    "            translated_words = dataset.loc[dataset[SOURCE_LANGUAGE] == source_word, TARGET_LANGUAGE].values[0]\n",
    "            if isinstance(translated_words, str):\n",
    "                translated_words = [translated_words]\n",
    "\n",
    "            # Build binary relevance list: 1 if correct, 0 otherwise\n",
    "            top_words = [target_words_list[idx] for idx in top_indices]\n",
    "            relevance = [1 if word in translated_words else 0 for word in top_words]\n",
    "            relevance_lists.append(relevance)\n",
    "\n",
    "        results[layer] = relevance_lists  # list of lists of 0/1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def compute_map_at_k(relevance_lists, k):\n",
    "    ap_scores = []\n",
    "    for rels in relevance_lists:\n",
    "        score = 0.0\n",
    "        hits = 0\n",
    "        for i in range(min(len(rels), k)):\n",
    "            if rels[i] == 1:\n",
    "                hits += 1\n",
    "                score += hits / (i + 1)\n",
    "        denom = min(k, sum(rels))\n",
    "        ap_scores.append(score / denom if denom > 0 else 0.0)\n",
    "    return np.mean(ap_scores)\n",
    "\n",
    "def compute_ndcg_at_k(relevance_lists, k):\n",
    "    def dcg(rels):\n",
    "        return sum([(2**rel - 1) / np.log2(idx + 2) for idx, rel in enumerate(rels[:k])])\n",
    "    \n",
    "    ndcg_scores = []\n",
    "    for rels in relevance_lists:\n",
    "        ideal_rels = sorted(rels, reverse=True)\n",
    "        denom = dcg(ideal_rels)\n",
    "        ndcg = dcg(rels) / denom if denom != 0 else 0.0\n",
    "        ndcg_scores.append(ndcg)\n",
    "    return np.mean(ndcg_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and language pairs\n",
    "models = [\"Tower-Babel/Babel-9B-Chat\", \"google/gemma-3-12b-it\", \"meta-llama/Llama-2-7b-chat-hf\"]\n",
    "languages = [\"English\", \"Korean\", \"German\"]\n",
    "language_pairs = [(src, tgt) for src in languages for tgt in languages if src != tgt]\n",
    "\n",
    "# Directory to save results\n",
    "results_dir = \"/home/hyujang/multilingual-inner-lexicon/output/RQ2/WordSimilarity\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Initialize results dictionary\n",
    "results_dict = {}\n",
    "\n",
    "# Run experiments for all models and language pairs\n",
    "for model_name in models:\n",
    "    # module = WordNonwordClassifier(\"English\", model_name)\n",
    "    model_name_simple = model_name.split(\"/\")[-1]\n",
    "    results_dict[model_name] = {}\n",
    "    for src, tgt in language_pairs:\n",
    "        print(f\"Processing {model_name} for {src}-{tgt}...\")\n",
    "        try:\n",
    "            csv_path = os.path.join(results_dir, f\"{model_name_simple}_{src}_{tgt}_metrics.csv\")\n",
    "            \n",
    "            # Check if CSV file already exists\n",
    "            if os.path.exists(csv_path):\n",
    "                print(f\"Loading existing results from {csv_path}...\")\n",
    "                layer_metrics = pd.read_csv(csv_path).to_dict(orient=\"list\")\n",
    "                results_dict[model_name][f\"{src}-{tgt}\"] = layer_metrics\n",
    "                continue  # Skip computation if file exists\n",
    "\n",
    "            # Prepare dataset\n",
    "            dataset = prepare_dataset(src, tgt)\n",
    "            source_words_list = dataset[src].tolist()\n",
    "            target_words_list = list(set([item for sublist in dataset[tgt] for item in sublist]))\n",
    "\n",
    "            # Extract hidden states\n",
    "            \n",
    "            # hidden_source = module.extract_token_i_hidden_states(inputs=source_words_list)\n",
    "            # hidden_target = module.extract_token_i_hidden_states(inputs=target_words_list)\n",
    "            hidden_source = extract_token_hidden_states(model_name, source_words_list)\n",
    "            hidden_target = extract_token_hidden_states(model_name, target_words_list)\n",
    "            # Compute alignment — should return per-layer relevance lists\n",
    "            alignment_results = compute_alignment(\n",
    "                src, tgt, source_words_list, target_words_list,\n",
    "                hidden_source, hidden_target, dataset, top_k=100  # Or another cutoff\n",
    "            )\n",
    "\n",
    "            # Expecting: alignment_results[layer] = list of binary relevance lists per query\n",
    "            layers = sorted(alignment_results.keys())\n",
    "            layer_metrics = {\"Layer\": [], \"Top-1 Accuracy\": [], \"MAP@100\": [], \"nDCG@100\": []}\n",
    "\n",
    "            for layer in layers:\n",
    "                relevance_lists = alignment_results[layer]  # Each: list of 0/1 for a source word’s ranking\n",
    "\n",
    "                top1_accuracy = np.mean([rels[0] for rels in relevance_lists if len(rels) > 0])\n",
    "                map_at_100 = compute_map_at_k(relevance_lists, k=100)\n",
    "                ndcg_at_100 = compute_ndcg_at_k(relevance_lists, k=100)\n",
    "\n",
    "                layer_metrics[\"Layer\"].append(layer)\n",
    "                layer_metrics[\"Top-1 Accuracy\"].append(top1_accuracy)\n",
    "                layer_metrics[\"MAP@100\"].append(map_at_100)\n",
    "                layer_metrics[\"nDCG@100\"].append(ndcg_at_100)\n",
    "\n",
    "            # Save all metrics\n",
    "            results_dict[model_name][f\"{src}-{tgt}\"] = layer_metrics\n",
    "\n",
    "            # Save to CSV immediately\n",
    "            pd.DataFrame(layer_metrics).to_csv(csv_path, index=False)\n",
    "\n",
    "            print(f\"Saved results for {model_name} ({src}-{tgt})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {model_name} ({src}-{tgt}): {e}\")\n",
    "\n",
    "# Save all results to a combined JSON file\n",
    "combined_json_path = os.path.join(results_dir, \"alignment_results_combined.json\")\n",
    "with open(combined_json_path, \"w\") as f:\n",
    "    json.dump(results_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define metrics and language pair groups\n",
    "metric = \"nDCG@100\"\n",
    "language_pair_groups = [\n",
    "    [(\"English\", \"Korean\"), (\"Korean\", \"English\")],\n",
    "    [(\"English\", \"German\"), (\"German\", \"English\")],\n",
    "    [(\"German\", \"Korean\"), (\"Korean\", \"German\")]\n",
    "]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(len(models), len(language_pair_groups), figsize=(20, 15), sharex=True, sharey=True)\n",
    "# fig.suptitle(f\"{metric} Across Layers\", fontsize=20)\n",
    "\n",
    "for i, pair_group in enumerate(language_pair_groups):\n",
    "    for j, model_name in enumerate(models):\n",
    "        ax = axes[i, j]\n",
    "        for src, tgt in pair_group:\n",
    "            key = f\"{src}-{tgt}\"\n",
    "            if key in results_dict[model_name]:\n",
    "                layer_metrics = results_dict[model_name][key]\n",
    "                layers = layer_metrics[\"Layer\"]\n",
    "                values = layer_metrics[metric]\n",
    "\n",
    "                # Plot retrieval rate\n",
    "                ax.plot(\n",
    "                    layers,\n",
    "                    values,\n",
    "                    marker='o',\n",
    "                    label=f\"{src} → {tgt}\",\n",
    "                    alpha=0.7\n",
    "                )\n",
    "                ax.set_title(f\"{model_name.split('/')[-1]}: {pair_group[0][0]}↔{pair_group[0][1]}\", fontsize=20)\n",
    "                ax.grid(True)\n",
    "\n",
    "        # Add labels\n",
    "        if i == len(models) - 1:\n",
    "            ax.set_xlabel(\"Layer\", fontsize=18)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(metric, fontsize=18)\n",
    "\n",
    "        # Add legend\n",
    "        ax.grid(True)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        ax.legend(title=\"Language Pair\", fontsize=14)\n",
    "\n",
    "# Adjust layout and show plot\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout for title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# metrics = [\"Top-1 Accuracy\", \"MAP@100\", \"nDCG@100\"]\n",
    "metric = \"nDCG@100\"\n",
    "\n",
    "# for metric in metrics:\n",
    "fig, axes = plt.subplots(len(models), len(language_pairs), figsize=(25, 10), sharex=True, sharey=True)\n",
    "fig.suptitle(f\"{metric} Across Layers\", fontsize=20)\n",
    "\n",
    "for i, model_name in enumerate(models):\n",
    "    for j, (src, tgt) in enumerate(language_pairs):\n",
    "        ax = axes[i, j]\n",
    "        key = f\"{src}-{tgt}\"\n",
    "        if key in results_dict[model_name]:\n",
    "            layer_metrics = results_dict[model_name][key]\n",
    "            layers = layer_metrics[\"Layer\"]\n",
    "            values = layer_metrics[metric]\n",
    "\n",
    "            ax.plot(layers, values, marker='o', label=metric)\n",
    "            ax.set_title(f\"{model_name.split('/')[-1]}: {src}-{tgt}\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        if i == len(models) - 1:\n",
    "            ax.set_xlabel(\"Layer\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(metric)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout for title\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
